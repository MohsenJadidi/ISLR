{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression in TensorFlow 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEKN75aE/gE0tiYNPIb0Be",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohsenJadidi/ISLR/blob/master/Logistic_Regression_in_TensorFlow_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GovsEJgo9HA"
      },
      "source": [
        "# Logistic Regression in TensorFlow 2.0 (MNIST Data set)\n",
        "\n",
        "Author: https://theclickreader.com/courses/tensorflow-2-for-deep-learning/lessons/logistic-regression-with-tensorflow/\n",
        "\n",
        "Modify by: MohammadMohsen Jadidi | email : mohsenjadidi@aut.ac.ir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFpk8TdtpyWp"
      },
      "source": [
        "## Read Data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-2Jj344pyBe",
        "outputId": "9974379c-b478-49c2-9f44-397bf3925149",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Load train and test data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Converting data to float32\n",
        "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
        "# Flatten images to 1-D vector of 784 features (28*28).\n",
        "x_train, x_test = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1)\n",
        "# Normalize images value from [0, 255] to [0, 1].\n",
        "x_train, x_test = x_train / 255., x_test / 255.\n",
        "\n",
        "# Batching \n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(5000).batch(256).prefetch(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkD9c5_Cq4bF"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkW_JLSto6we"
      },
      "source": [
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.W = tf.Variable(tf.ones([28*28, 10]), name=\"weight\")\n",
        "        self.b = tf.Variable(tf.zeros([10]), name=\"bias\")\n",
        "    def __call__(self, x):\n",
        "        return tf.nn.softmax(tf.matmul(x, self.W) + self.b)\n",
        "    \n",
        "   \n",
        "def loss(y_pred, y_true):\n",
        "    # Encode label to a one hot vector\n",
        "    y_true = tf.one_hot(y_true, depth=10)\n",
        "    \n",
        "    # Clip prediction values to avoid log(0) error\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
        "    \n",
        "    # Compute cross-entropy\n",
        "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred),1))\n",
        "def accuracy(y_pred, y_true):\n",
        "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "# Stochastic gradient descent optimizer.\n",
        "optimizer = tf.optimizers.SGD(lr = 0.1)\n",
        "    \n",
        "\n",
        "def train(model, x, y):\n",
        "    with tf.GradientTape() as t:\n",
        "        pred = model(x)\n",
        "        current_loss = loss(pred, y)\n",
        "    # Compute gradients\n",
        "    gradients = t.gradient(current_loss, [model.W, model.b])\n",
        "    \n",
        "    # Update W and b following gradients.\n",
        "    optimizer.apply_gradients(zip(gradients, [model.W, model.b]))"
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}